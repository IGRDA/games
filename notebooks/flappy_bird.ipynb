{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DQN...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/DQN_1\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.5     |\n",
      "|    ep_rew_mean      | -13.9    |\n",
      "|    exploration_rate | 0.846    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 2554     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 162      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0837   |\n",
      "|    n_updates        | 15       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -11.1    |\n",
      "|    exploration_rate | 0.675    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 2982     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 342      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0757   |\n",
      "|    n_updates        | 60       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.1     |\n",
      "|    ep_rew_mean      | -13.7    |\n",
      "|    exploration_rate | 0.497    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 3162     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 529      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 107      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.7     |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.321    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 3215     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 715      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0827   |\n",
      "|    n_updates        | 153      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.1     |\n",
      "|    ep_rew_mean      | -13.6    |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 3275     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 903      |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0782   |\n",
      "|    n_updates        | 200      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.7     |\n",
      "|    ep_rew_mean      | -13.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 3304     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1097     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0863   |\n",
      "|    n_updates        | 249      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44.9     |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 3315     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1256     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.05     |\n",
      "|    n_updates        | 288      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.4     |\n",
      "|    ep_rew_mean      | -10.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1389     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0727   |\n",
      "|    n_updates        | 322      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.2     |\n",
      "|    ep_rew_mean      | -10.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 3310     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1521     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0805   |\n",
      "|    n_updates        | 355      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.3     |\n",
      "|    ep_rew_mean      | -9.67    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 3314     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1653     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0593   |\n",
      "|    n_updates        | 388      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.6     |\n",
      "|    ep_rew_mean      | -9.96    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 3319     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1785     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0569   |\n",
      "|    n_updates        | 421      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40       |\n",
      "|    ep_rew_mean      | -11      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 3319     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1920     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0471   |\n",
      "|    n_updates        | 454      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -11.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 3294     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2071     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 492      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.8     |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 3286     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2231     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 532      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.7     |\n",
      "|    ep_rew_mean      | -11.2    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 3257     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2381     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.054    |\n",
      "|    n_updates        | 570      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.5     |\n",
      "|    ep_rew_mean      | -10.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 3192     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2526     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0412   |\n",
      "|    n_updates        | 606      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -10.5    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 3186     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2673     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0258   |\n",
      "|    n_updates        | 643      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -10.8    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2816     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 678      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39       |\n",
      "|    ep_rew_mean      | -10.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 3172     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2961     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0187   |\n",
      "|    n_updates        | 715      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.1     |\n",
      "|    ep_rew_mean      | -10.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 3185     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3125     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0245   |\n",
      "|    n_updates        | 756      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.2     |\n",
      "|    ep_rew_mean      | -9.9     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 3197     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3297     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 799      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.3     |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 3204     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3458     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.027    |\n",
      "|    n_updates        | 839      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.6     |\n",
      "|    ep_rew_mean      | -10.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 3142     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3640     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0082   |\n",
      "|    n_updates        | 884      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 39.9     |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 3828     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00959  |\n",
      "|    n_updates        | 931      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4006     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0123   |\n",
      "|    n_updates        | 976      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -9.88    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 3126     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4188     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.022    |\n",
      "|    n_updates        | 1021     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.3     |\n",
      "|    ep_rew_mean      | -9.85    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 3097     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4376     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.012    |\n",
      "|    n_updates        | 1068     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.2     |\n",
      "|    ep_rew_mean      | -9.98    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 3108     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4551     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0246   |\n",
      "|    n_updates        | 1112     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -10.4    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 3100     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4727     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 1156     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.1     |\n",
      "|    ep_rew_mean      | -10.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 3113     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 4914     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00866  |\n",
      "|    n_updates        | 1203     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| timesteps           | 5000     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0157   |\n",
      "|    n_updates        | 1224     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 40.7     |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 3114     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5169     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00573  |\n",
      "|    n_updates        | 1267     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41       |\n",
      "|    ep_rew_mean      | -10.3    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 3116     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5353     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0175   |\n",
      "|    n_updates        | 1313     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 41.5     |\n",
      "|    ep_rew_mean      | -10.6    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 3128     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5541     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0114   |\n",
      "|    n_updates        | 1360     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 42.8     |\n",
      "|    ep_rew_mean      | -10.1    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 3132     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5798     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0214   |\n",
      "|    n_updates        | 1424     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 43.2     |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 3130     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 5978     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0182   |\n",
      "|    n_updates        | 1469     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 44       |\n",
      "|    ep_rew_mean      | -9.62    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 3129     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 6182     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 1520     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.5     |\n",
      "|    ep_rew_mean      | -8.88    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 3136     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 6472     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.055    |\n",
      "|    n_updates        | 1592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 45.8     |\n",
      "|    ep_rew_mean      | -8.57    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 3114     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 6648     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0412   |\n",
      "|    n_updates        | 1636     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46       |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 3106     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 6836     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0374   |\n",
      "|    n_updates        | 1683     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.4     |\n",
      "|    ep_rew_mean      | -8.86    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 3105     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 7024     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0162   |\n",
      "|    n_updates        | 1730     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 46.9     |\n",
      "|    ep_rew_mean      | -9.19    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 3086     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 7216     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 1778     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.3     |\n",
      "|    ep_rew_mean      | -9.19    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 3073     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 7404     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00708  |\n",
      "|    n_updates        | 1825     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 47.8     |\n",
      "|    ep_rew_mean      | -8.2     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 3070     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 7594     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0134   |\n",
      "|    n_updates        | 1873     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.2     |\n",
      "|    ep_rew_mean      | -8.56    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 3059     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 7782     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0423   |\n",
      "|    n_updates        | 1920     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.5     |\n",
      "|    ep_rew_mean      | -8.54    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 7974     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0607   |\n",
      "|    n_updates        | 1968     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.6     |\n",
      "|    ep_rew_mean      | -9.23    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 3055     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8162     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0183   |\n",
      "|    n_updates        | 2015     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 48.9     |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 3002     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8350     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0109   |\n",
      "|    n_updates        | 2062     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49       |\n",
      "|    ep_rew_mean      | -8.6     |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 2997     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8537     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 2109     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.6     |\n",
      "|    ep_rew_mean      | -8.49    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 2974     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 8784     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.034    |\n",
      "|    n_updates        | 2170     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 49.7     |\n",
      "|    ep_rew_mean      | -8.22    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 2967     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 8980     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0416   |\n",
      "|    n_updates        | 2219     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.5     |\n",
      "|    ep_rew_mean      | -7.71    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 2975     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9234     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0135   |\n",
      "|    n_updates        | 2283     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.5     |\n",
      "|    ep_rew_mean      | -7.88    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 2973     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9422     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0136   |\n",
      "|    n_updates        | 2330     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.6     |\n",
      "|    ep_rew_mean      | -7.87    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 2972     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9609     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.086    |\n",
      "|    n_updates        | 2377     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.7     |\n",
      "|    ep_rew_mean      | -7.55    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 2954     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9794     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.025    |\n",
      "|    n_updates        | 2423     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 50.5     |\n",
      "|    ep_rew_mean      | -7.27    |\n",
      "|    exploration_rate | 0.05     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 2958     |\n",
      "|    time_elapsed     | 3        |\n",
      "|    total_timesteps  | 9969     |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0274   |\n",
      "|    n_updates        | 2467     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    exploration_rate | 0.05     |\n",
      "| timesteps           | 10000    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0204   |\n",
      "|    n_updates        | 2474     |\n",
      "----------------------------------\n",
      "Training for DQN completed. You can monitor using tensorboard --logdir=./logs\n",
      "Training PPO...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 38.3     |\n",
      "|    ep_rew_mean     | -9.36    |\n",
      "| time/              |          |\n",
      "|    fps             | 5067     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 39.3        |\n",
      "|    ep_rew_mean          | -9.42       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3285        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013196027 |\n",
      "|    clip_fraction        | 0.0267      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.684      |\n",
      "|    explained_variance   | 0.00983     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 2.18        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00263    |\n",
      "|    value_loss           | 10.6        |\n",
      "-----------------------------------------\n",
      "-------------------------------------------\n",
      "| timesteps               | 5000          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00015431538 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -0.682        |\n",
      "|    explained_variance   | 0.492         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 4.23          |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | 0.000159      |\n",
      "|    value_loss           | 6.74          |\n",
      "-------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 40.4     |\n",
      "|    ep_rew_mean     | -8.59    |\n",
      "| time/              |          |\n",
      "|    fps             | 2926     |\n",
      "|    iterations      | 3        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 6144     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 41.3        |\n",
      "|    ep_rew_mean          | -7.46       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2774        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004397382 |\n",
      "|    clip_fraction        | 0.0148      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.652      |\n",
      "|    explained_variance   | 0.741       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.28        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.00341    |\n",
      "|    value_loss           | 6.94        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| timesteps               | 10000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035050632 |\n",
      "|    clip_fraction        | 0.00288      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.642       |\n",
      "|    explained_variance   | 0.82         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.05         |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000409    |\n",
      "|    value_loss           | 6.05         |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 42.7     |\n",
      "|    ep_rew_mean     | -6.74    |\n",
      "| time/              |          |\n",
      "|    fps             | 2684     |\n",
      "|    iterations      | 5        |\n",
      "|    time_elapsed    | 3        |\n",
      "|    total_timesteps | 10240    |\n",
      "---------------------------------\n",
      "Training for PPO completed. You can monitor using tensorboard --logdir=./logs\n",
      "Training A2C...\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to ./logs/A2C_1\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 51.1     |\n",
      "|    ep_rew_mean        | -3.84    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1837     |\n",
      "|    iterations         | 100      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 500      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.629   |\n",
      "|    explained_variance | -0.353   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 99       |\n",
      "|    policy_loss        | 0.589    |\n",
      "|    value_loss         | 1.1      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 47.1     |\n",
      "|    ep_rew_mean        | -5.98    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1871     |\n",
      "|    iterations         | 200      |\n",
      "|    time_elapsed       | 0        |\n",
      "|    total_timesteps    | 1000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.581   |\n",
      "|    explained_variance | -4.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 199      |\n",
      "|    policy_loss        | -0.157   |\n",
      "|    value_loss         | 0.168    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 42.3      |\n",
      "|    ep_rew_mean        | -4.18     |\n",
      "| time/                 |           |\n",
      "|    fps                | 1873      |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 0         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -0.0513   |\n",
      "|    explained_variance | -0.0726   |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -0.000769 |\n",
      "|    value_loss         | 0.0113    |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.6     |\n",
      "|    ep_rew_mean        | -3.94    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1857     |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0949  |\n",
      "|    explained_variance | -3.75    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | 0.00116  |\n",
      "|    value_loss         | 0.0719   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.6     |\n",
      "|    ep_rew_mean        | -3.48    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1829     |\n",
      "|    iterations         | 500      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 2500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.657   |\n",
      "|    explained_variance | 0.118    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 499      |\n",
      "|    policy_loss        | -1.71    |\n",
      "|    value_loss         | 3.87     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37       |\n",
      "|    ep_rew_mean        | -3.79    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1771     |\n",
      "|    iterations         | 600      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 3000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.672   |\n",
      "|    explained_variance | -0.0738  |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 599      |\n",
      "|    policy_loss        | -0.6     |\n",
      "|    value_loss         | 2.4      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 37.8     |\n",
      "|    ep_rew_mean        | -3.13    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1798     |\n",
      "|    iterations         | 700      |\n",
      "|    time_elapsed       | 1        |\n",
      "|    total_timesteps    | 3500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.455   |\n",
      "|    explained_variance | -0.824   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 699      |\n",
      "|    policy_loss        | -0.875   |\n",
      "|    value_loss         | 0.674    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38       |\n",
      "|    ep_rew_mean        | -2.47    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1809     |\n",
      "|    iterations         | 800      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.312   |\n",
      "|    explained_variance | -0.103   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 799      |\n",
      "|    policy_loss        | -0.0838  |\n",
      "|    value_loss         | 0.837    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 35.8     |\n",
      "|    ep_rew_mean        | -1.9     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1782     |\n",
      "|    iterations         | 900      |\n",
      "|    time_elapsed       | 2        |\n",
      "|    total_timesteps    | 4500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.0888  |\n",
      "|    explained_variance | 0.813    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 899      |\n",
      "|    policy_loss        | -0.00452 |\n",
      "|    value_loss         | 0.192    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| timesteps             | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.574   |\n",
      "|    explained_variance | -0.118   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -0.993   |\n",
      "|    value_loss         | 5.76     |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 35.5     |\n",
      "|    ep_rew_mean     | -1.85    |\n",
      "| time/              |          |\n",
      "|    fps             | 1804     |\n",
      "|    iterations      | 1000     |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 5000     |\n",
      "---------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 38.1     |\n",
      "|    ep_rew_mean        | -1.68    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1813     |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.218   |\n",
      "|    explained_variance | 0.575    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -0.0617  |\n",
      "|    value_loss         | 2.75     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.2     |\n",
      "|    ep_rew_mean        | -1.34    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1820     |\n",
      "|    iterations         | 1200     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 6000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.534   |\n",
      "|    explained_variance | 0.856    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1199     |\n",
      "|    policy_loss        | 0.307    |\n",
      "|    value_loss         | 0.426    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 41.5     |\n",
      "|    ep_rew_mean        | -1.52    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1822     |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.226   |\n",
      "|    explained_variance | -0.03    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -0.163   |\n",
      "|    value_loss         | 8.23     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.9     |\n",
      "|    ep_rew_mean        | -1.39    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1807     |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 3        |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.225   |\n",
      "|    explained_variance | -0.423   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | -0.603   |\n",
      "|    value_loss         | 0.515    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.8     |\n",
      "|    ep_rew_mean        | -2.03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1805     |\n",
      "|    iterations         | 1500     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 7500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.626   |\n",
      "|    explained_variance | -1.35    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1499     |\n",
      "|    policy_loss        | -0.364   |\n",
      "|    value_loss         | 1.13     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.8     |\n",
      "|    ep_rew_mean        | -2.46    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1813     |\n",
      "|    iterations         | 1600     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 8000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.665   |\n",
      "|    explained_variance | -0.362   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1599     |\n",
      "|    policy_loss        | 0.205    |\n",
      "|    value_loss         | 0.233    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.8     |\n",
      "|    ep_rew_mean        | -3.1     |\n",
      "| time/                 |          |\n",
      "|    fps                | 1808     |\n",
      "|    iterations         | 1700     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 8500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.574   |\n",
      "|    explained_variance | 0.0448   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1699     |\n",
      "|    policy_loss        | 2.72     |\n",
      "|    value_loss         | 12.4     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 40.4     |\n",
      "|    ep_rew_mean        | -3.41    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1811     |\n",
      "|    iterations         | 1800     |\n",
      "|    time_elapsed       | 4        |\n",
      "|    total_timesteps    | 9000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.193   |\n",
      "|    explained_variance | -0.169   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1799     |\n",
      "|    policy_loss        | -0.0796  |\n",
      "|    value_loss         | 3.03     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 39.5     |\n",
      "|    ep_rew_mean        | -3.35    |\n",
      "| time/                 |          |\n",
      "|    fps                | 1808     |\n",
      "|    iterations         | 1900     |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 9500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.652   |\n",
      "|    explained_variance | 0.202    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 0.479    |\n",
      "|    value_loss         | 0.985    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| timesteps             | 10000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -0.525   |\n",
      "|    explained_variance | 0.739    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1999     |\n",
      "|    policy_loss        | 0.145    |\n",
      "|    value_loss         | 0.032    |\n",
      "------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 39.5     |\n",
      "|    ep_rew_mean     | -3.83    |\n",
      "| time/              |          |\n",
      "|    fps             | 1815     |\n",
      "|    iterations      | 2000     |\n",
      "|    time_elapsed    | 5        |\n",
      "|    total_timesteps | 10000    |\n",
      "---------------------------------\n",
      "Training for A2C completed. You can monitor using tensorboard --logdir=./logs\n",
      "Playing with DQN model...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'flappy_bird_dqn.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 189\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m algo_name, algo_class \u001b[38;5;129;01min\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlaying with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malgo_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[43malgo_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mflappy_bird_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43malgo_name\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     play_game_in_notebook(FlappyBirdEnv(), trained_model, episodes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, render_delay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n",
      "File \u001b[0;32m~/Personal/games/venv-games/lib/python3.11/site-packages/stable_baselines3/common/base_class.py:680\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m== CURRENT SYSTEM INFO ==\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    678\u001b[0m     get_system_info()\n\u001b[0;32m--> 680\u001b[0m data, params, pytorch_variables \u001b[38;5;241m=\u001b[39m \u001b[43mload_from_zip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_system_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_system_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo data found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo params found in the saved file\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Personal/games/venv-games/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:403\u001b[0m, in \u001b[0;36mload_from_zip_file\u001b[0;34m(load_path, load_data, custom_objects, device, verbose, print_system_info)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_zip_file\u001b[39m(\n\u001b[1;32m    377\u001b[0m     load_path: Union[\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath, io\u001b[38;5;241m.\u001b[39mBufferedIOBase],\n\u001b[1;32m    378\u001b[0m     load_data: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     print_system_info: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]], TensorDict, Optional[TensorDict]]:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Load model data from a .zip archive\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;124;03m        and dict of pytorch variables\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mopen_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mload_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# set device to cpu if cuda is not available\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     device \u001b[38;5;241m=\u001b[39m get_device(device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/functools.py:909\u001b[0m, in \u001b[0;36msingledispatch.<locals>.wrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires at least \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    907\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1 positional argument\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 909\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/games/venv-games/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:240\u001b[0m, in \u001b[0;36mopen_path_str\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;129m@open_path\u001b[39m\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;28mstr\u001b[39m)\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mopen_path_str\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, mode: \u001b[38;5;28mstr\u001b[39m, verbose: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, suffix: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m io\u001b[38;5;241m.\u001b[39mBufferedIOBase:\n\u001b[1;32m    227\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03m    Open a path given by a string. If writing to the path, the function ensures\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;124;03m    that the path exists.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m    :return:\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpathlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/games/venv-games/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:291\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    285\u001b[0m         path\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# if opening was successful uses the open_path() function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# if opening failed with IsADirectory|FileNotFound, calls open_path_pathlib\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m#   with corrections\u001b[39;00m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;66;03m# if reading failed with FileNotFoundError, calls open_path_pathlib with suffix\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopen_path_pathlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Personal/games/venv-games/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:272\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    270\u001b[0m             path, suffix \u001b[38;5;241m=\u001b[39m newpath, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Personal/games/venv-games/lib/python3.11/site-packages/stable_baselines3/common/save_util.py:264\u001b[0m, in \u001b[0;36mopen_path_pathlib\u001b[0;34m(path, mode, verbose, suffix)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m open_path(\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, mode, verbose, suffix)\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m suffix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m suffix \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py:1044\u001b[0m, in \u001b[0;36mPath.open\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1043\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mtext_encoding(encoding)\n\u001b[0;32m-> 1044\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flappy_bird_dqn.zip'"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import pygame\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Custom callback to log every `x` steps to TensorBoard\n",
    "class CustomTensorBoardCallback(BaseCallback):\n",
    "    def __init__(self, save_freq: int, verbose=0):\n",
    "        super().__init__(verbose)\n",
    "        self.save_freq = save_freq\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        # Log to TensorBoard every `save_freq` steps\n",
    "        if self.num_timesteps % self.save_freq == 0:\n",
    "            self.logger.record('timesteps', self.num_timesteps)\n",
    "            self.logger.dump(self.num_timesteps)\n",
    "        return True\n",
    "\n",
    "class FlappyBirdEnv(gym.Env):\n",
    "    \"\"\"Custom Environment for Flappy Bird Game.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.screen_width = 288\n",
    "        self.screen_height = 512\n",
    "        self.bird_width = 34\n",
    "        self.bird_height = 24\n",
    "        self.pipe_width = 52\n",
    "        self.pipe_gap = 100\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)  # Flap or not\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=np.array([0, 0, -1, 0, 0], dtype=np.float32),\n",
    "            high=np.array([1, 1, 1, 1, 1], dtype=np.float32)\n",
    "        )\n",
    "\n",
    "        self.screen = None\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.bird_pos = [self.screen_width * 0.2, self.screen_height / 2]\n",
    "        self.bird_velocity = 0\n",
    "        self.pipe_pos = [self.screen_width, random.randint(100, 400)]\n",
    "        self.score = 0\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        if action:\n",
    "            self.bird_velocity = -9\n",
    "\n",
    "        self.bird_velocity += 1\n",
    "        self.bird_pos[1] += self.bird_velocity\n",
    "\n",
    "        self.pipe_pos[0] -= 5\n",
    "        if self.pipe_pos[0] < -self.pipe_width:\n",
    "            self.pipe_pos = [self.screen_width, random.randint(100, 400)]\n",
    "            self.score += 1\n",
    "\n",
    "        done = self._check_collision()\n",
    "        reward = self._calculate_reward(done)\n",
    "        return self._get_obs(), reward, done, False, {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return np.array([\n",
    "            self.bird_pos[0] / self.screen_width,\n",
    "            self.bird_pos[1] / self.screen_height,\n",
    "            np.clip(self.bird_velocity / 10.0, -1, 1),\n",
    "            self.pipe_pos[0] / self.screen_width,\n",
    "            self.pipe_pos[1] / self.screen_height,\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "    def _check_collision(self):\n",
    "        if self.bird_pos[1] < 0 or self.bird_pos[1] > self.screen_height - self.bird_height:\n",
    "            return True\n",
    "\n",
    "        if (self.pipe_pos[0] < self.bird_pos[0] < self.pipe_pos[0] + self.pipe_width and\n",
    "            (self.bird_pos[1] < self.pipe_pos[1] - self.pipe_gap / 2 or\n",
    "             self.bird_pos[1] + self.bird_height > self.pipe_pos[1] + self.pipe_gap / 2)):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _calculate_reward(self, done):\n",
    "        if done:\n",
    "            return -1.0\n",
    "\n",
    "        reward = 0.1\n",
    "        mid_screen_y = self.screen_height / 2\n",
    "        distance_to_center = abs(self.bird_pos[1] - mid_screen_y)\n",
    "        reward += 0.1 * (1 - distance_to_center / mid_screen_y)\n",
    "\n",
    "        pipe_center_y = self.pipe_pos[1]\n",
    "        distance_to_pipe_gap = abs(self.bird_pos[1] - pipe_center_y)\n",
    "        reward += 0.2 * (1 - distance_to_pipe_gap / (self.pipe_gap / 2))\n",
    "\n",
    "        if self.pipe_pos[0] + self.pipe_width < self.bird_pos[0]:\n",
    "            reward += 1.0\n",
    "\n",
    "        return reward\n",
    "\n",
    "    def render(self):\n",
    "        if self.screen is None:\n",
    "            pygame.init()\n",
    "            self.screen = pygame.display.set_mode((self.screen_width, self.screen_height), pygame.NOFRAME)\n",
    "\n",
    "        self.screen.fill((135, 206, 235))\n",
    "        bird_rect = pygame.Rect(self.bird_pos[0], self.bird_pos[1], self.bird_width, self.bird_height)\n",
    "        pygame.draw.rect(self.screen, (255, 255, 0), bird_rect)\n",
    "\n",
    "        upper_pipe_rect = pygame.Rect(self.pipe_pos[0], 0, self.pipe_width, self.pipe_pos[1] - self.pipe_gap / 2)\n",
    "        lower_pipe_rect = pygame.Rect(self.pipe_pos[0], self.pipe_pos[1] + self.pipe_gap / 2, self.pipe_width, self.screen_height)\n",
    "        pygame.draw.rect(self.screen, (0, 255, 0), upper_pipe_rect)\n",
    "        pygame.draw.rect(self.screen, (0, 255, 0), lower_pipe_rect)\n",
    "\n",
    "        return pygame.surfarray.array3d(self.screen).swapaxes(0, 1)\n",
    "\n",
    "    def close(self):\n",
    "        if self.screen:\n",
    "            pygame.quit()\n",
    "            self.screen = None\n",
    "\n",
    "# Set up logging for TensorBoard\n",
    "log_dir = \"./logs\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# Define the algorithms to test\n",
    "algorithms = {\n",
    "    \"DQN\": DQN,\n",
    "    \"PPO\": PPO,\n",
    "    \"A2C\": A2C\n",
    "}\n",
    "\n",
    "# Specify the number of steps to log to TensorBoard\n",
    "log_freq = 5000  # Save to TensorBoard every 1000 steps\n",
    "\n",
    "# Loop through different algorithms and train them\n",
    "for algo_name, algo_class in algorithms.items():\n",
    "    print(f\"Training {algo_name}...\")\n",
    "    \n",
    "    \n",
    "    # Ensure a fresh environment for each algorithm\n",
    "    env = FlappyBirdEnv()  \n",
    "    check_env(env)  # Re-check the environment to avoid misconfiguration\n",
    "    \n",
    "    model = algo_class(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "    \n",
    "    # Add the custom callback to log every `log_freq` steps\n",
    "    callback = CustomTensorBoardCallback(save_freq=log_freq)\n",
    "    \n",
    "    model.learn(total_timesteps=100000, callback=callback)\n",
    "    \n",
    "    # Close the environment explicitly\n",
    "    env.close()\n",
    "    env.reset()\n",
    "    print(f\"Training for {algo_name} completed. You can monitor using tensorboard --logdir=./logs\")\n",
    "\n",
    "\n",
    "def play_game_in_notebook(env, model, episodes=1, render_delay=0.1):\n",
    "    \"\"\"Play the game using the trained model and display frames in a Jupyter Notebook.\"\"\"\n",
    "    for _ in range(episodes):\n",
    "        obs, _ = env.reset()\n",
    "        done = False\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            obs, _, done, _, _ = env.step(action)\n",
    "\n",
    "            frame = env.render()\n",
    "            if isinstance(frame, np.ndarray):\n",
    "                plt.imshow(frame)\n",
    "                plt.axis('off')\n",
    "                display(plt.gcf())\n",
    "                plt.close()\n",
    "                pygame.time.delay(int(render_delay * 1000))\n",
    "                clear_output(wait=True)\n",
    "\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 7213), started 0:00:36 ago. (Use '!kill 7213' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-17018eaa90f880ed\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-17018eaa90f880ed\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs --host localhost --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DQN, PPO, A2C\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "model.learn(total_timesteps=10000)\n",
    "model.save(f\"models/flappy_bird_{algo_name.lower()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and play with trained models\n",
    "for algo_name, algo_class in algorithms.items():\n",
    "    print(f\"Playing with {algo_name} model...\")\n",
    "    trained_model = algo_class.load(f\"flappy_bird_{algo_name.lower()}\")\n",
    "    play_game_in_notebook(FlappyBirdEnv(), trained_model, episodes=3, render_delay=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-games",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
